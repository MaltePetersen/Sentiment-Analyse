{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Sentiment Analyse von McDonalds Reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zielsetzung:\n",
    "Die Reviews haben die Labels '1 star', '2 stars', '3 stars', '4 stars' und '5 stars'. \n",
    "Das reine Raten, wie der Reviewer bewertet hat, würde eine 20% Prozentige Trefferwahrscheinlichkeit haben. Dieses Benchmarkt muss unsere Analyse mindestens knacken um Sinnvoll zu sein. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:27:17.729118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# use graphics in retina format\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorbereitung inkl. Behandlung bekannter Probleme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !kaggle datasets download -d nelgiriyewithana/mcdonalds-store-reviews\n",
    "if os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Unziping dataset...\")\n",
    "    !unzip -n mcdonalds-store-reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>category</th>\n",
       "      <th>store_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id  store_name              category  \\\n",
       "0            1  McDonald's  Fast food restaurant   \n",
       "1            2  McDonald's  Fast food restaurant   \n",
       "2            3  McDonald's  Fast food restaurant   \n",
       "3            4  McDonald's  Fast food restaurant   \n",
       "4            5  McDonald's  Fast food restaurant   \n",
       "\n",
       "                                       store_address  latitude   longitude  \\\n",
       "0  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "1  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "2  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "3  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "4  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "\n",
       "  rating_count   review_time  \\\n",
       "0        1,240  3 months ago   \n",
       "1        1,240    5 days ago   \n",
       "2        1,240    5 days ago   \n",
       "3        1,240   a month ago   \n",
       "4        1,240  2 months ago   \n",
       "\n",
       "                                              review   rating  \n",
       "0  Why does it look like someone spit on my food?...   1 star  \n",
       "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
       "2  Made a mobile order got to the speaker and che...   1 star  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
       "4  I repeat my order 3 times in the drive thru, a...   1 star  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('McDonald_s_Reviews.csv', encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding der Daten\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Umgang mit Strings als Label\n",
    "Star Ratings werden gerade noch als 1 Star String bis zu einem 5 star String gespeichert. Mit einem numerischen System können neuronale Netzwerke besser umgehen, deshalb formatiere ich die labels zu interges zwischen 1 und 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df['review'].to_numpy()\n",
    "label_data_strings = df['rating']\n",
    "label_data = np.array([int(item.split()[0]) for item in label_data_strings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Verteilung der Ratings besser zu verstehen koennen wir die Daten visualieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(label_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilung in Trainings und Validierungsdaten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(train_data, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text zu Dictonary Repräsentationen umbauen\n",
    "Als Best Practice für Word Classification gibt das Buch Deep Learning with Python die Nutzung von 20000 Token an.\n",
    "Als Vectorication Mehotik. N-Gramme sind Sequenzen von aufeinanderfolgenden Elementen in einer gegebenen Textsequenz. \n",
    "Ein N-Gramm mit einem Wert von N besteht aus N aufeinanderfolgenden Elementen, die in der Regel Wörter oder Zeichen sind. Zum Beispiel besteht ein 2-Gramm (auch Bigramm genannt) aus zwei aufeinanderfolgenden Wörtern in einem Text, während ein 3-Gramm (Trigramm) aus drei aufeinanderfolgenden Wörtern besteht.\n",
    "\n",
    "Außerdem nutzen wir eine Multi-Hot-Kodierung als Ausgabe.\n",
    "Bei der Multi-Hot-Kodierung wird für jedes Merkmal eine binäre Darstellung verwendet, bei der jedes Merkmal durch eine Position im Vektor repräsentiert wird. Jede Position im Vektor steht für eine mögliche Kategorie des Merkmals. Wenn ein bestimmtes Element eines Merkmals vorhanden ist, wird der entsprechende Wert in der Vektorrepräsentation auf 1 gesetzt. Andernfalls wird der Wert auf 0 gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    " max_tokens=20000,\n",
    "ngrams=3,\n",
    " output_mode=\"multi_hot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization.adapt(train_data) \n",
    "text_vectorization.adapt(test_data) \n",
    "\n",
    "multi_hot_train_data = text_vectorization(train_data)\n",
    "multi_hot_test_data = text_vectorization(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Encoding der Lables\n",
    "Multi Hot Encoding nutzen wir auch für die Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_one_hot = tf.one_hot(train_label, 5)\n",
    "train_label_one_hot.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung eines entsprechenden künstlichen neuronalen Models sowie geeigente Benchmarks\n",
    "Damit wir hier ein Softmax output Layer nutzen können um in 5 Klassen die Daten Klassifizieren können.\n",
    "Als Besonderheit nutzen wir noch ein Drop out Layer. \n",
    "Ein Dropout-Layer ist eine spezielle Art von Schicht in einem neuronalen Netzwerk, die dazu dient, Overfitting (Überanpassung) zu reduzieren. Overfitting tritt auf, wenn ein neuronales Netzwerk sehr gut auf die Trainingsdaten passt, aber eine schlechte Leistung auf neuen, unbekannten Daten zeigt.\n",
    "\n",
    "Der Dropout-Layer funktioniert, indem er während des Trainings zufällig eine bestimmte Anzahl von Ausgabefunktionen (Neuronen) \"auslässt\" oder \"fallen lässt\". Das bedeutet, dass diese Neuronen während eines bestimmten Trainingsdurchlaufs keine Informationen an die nachfolgende Schicht weitergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1280064   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,282,757\n",
      "Trainable params: 1,282,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(max_tokens=20000, hidden_dim=64):\n",
    " inputs = keras.Input(shape=(max_tokens,))\n",
    " x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    " x = layers.Dense(32, activation=\"relu\")(x)\n",
    " x = layers.Dropout(0.5)(x)\n",
    " x = layers.Dense(16, activation=\"relu\")(x)\n",
    " outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
    " model = keras.Model(inputs, outputs)\n",
    " model.compile(optimizer=\"rmsprop\",\n",
    " loss=\"binary_crossentropy\",\n",
    " metrics=[\"accuracy\"], \n",
    " )\n",
    " return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Durchführung von In-sample und Out-of-sample Prognosen sowie Bestimmungen sowie Bestimmung der Prognossegüter anhand geeigneter Metriken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "501/501 [==============================] - 9s 16ms/step - loss: 0.3422 - accuracy: 0.3673 - val_loss: 0.2560 - val_accuracy: 0.4566\n",
      "Epoch 2/10\n",
      "501/501 [==============================] - 8s 17ms/step - loss: 0.2406 - accuracy: 0.4695 - val_loss: 0.2426 - val_accuracy: 0.4680\n",
      "Epoch 3/10\n",
      "501/501 [==============================] - 8s 15ms/step - loss: 0.2109 - accuracy: 0.5103 - val_loss: 0.2423 - val_accuracy: 0.4734\n",
      "Epoch 4/10\n",
      "501/501 [==============================] - 7s 14ms/step - loss: 0.1814 - accuracy: 0.5440 - val_loss: 0.2613 - val_accuracy: 0.4784\n",
      "Epoch 5/10\n",
      "501/501 [==============================] - 8s 15ms/step - loss: 0.1578 - accuracy: 0.5711 - val_loss: 0.2781 - val_accuracy: 0.4737\n",
      "Epoch 6/10\n",
      "501/501 [==============================] - 9s 18ms/step - loss: 0.1404 - accuracy: 0.5877 - val_loss: 0.2906 - val_accuracy: 0.4709\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Metric to monitor\n",
    "        patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True,  # Restore the weights of the best epoch\n",
    "    )\n",
    "]\n",
    "history = model.fit(multi_hot_train_data, train_label_one_hot, validation_split=0.4, epochs=10, callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_history_metrics\n",
    "plot_history_metrics(history, ['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.4642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24722281098365784, 0.4642215669155121]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_one_hot = tf.one_hot(test_label, 5)\n",
    "model.evaluate(multi_hot_test_data,test_label_one_hot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Wir kommen auf Out-of Samlple accuracy von 45%. Als Ziel haben wir uns 20 % Prozent gesetzt, weil wir 5 verschiedene Lables haben und alles drunter nur Raten wäre. Somit hat unsere Analyse das Ziel erreicht."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
