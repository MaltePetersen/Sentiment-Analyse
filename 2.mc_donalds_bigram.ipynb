{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Sentiment Analyse von McDonalds Reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zielsetzung:\n",
    "Die Reviews haben die Labels '1 star', '2 stars', '3 stars', '4 stars' und '5 stars'. \n",
    "Das reine Raten, wie der Reviewer bewertet hat, würde eine 20% Prozentige Trefferwahrscheinlichkeit haben. Dieses Benchmarkt muss unsere Analyse mindestens knacken um Sinnvoll zu sein. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# use graphics in retina format\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorbereitung inkl. Behandlung bekannter Probleme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !kaggle datasets download -d nelgiriyewithana/mcdonalds-store-reviews\n",
    "if os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Unziping dataset...\")\n",
    "    !unzip -n mcdonalds-store-reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('McDonald_s_Reviews.csv', encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review', 'rating']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_utils import clean_text\n",
    "\n",
    "df['review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding der Daten\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Umgang mit Strings als Label\n",
    "Star Ratings werden gerade noch als 1 Star String bis zu einem 5 star String gespeichert. Mit einem numerischen System können neuronale Netzwerke besser umgehen, deshalb formatiere ich die labels zu interges zwischen 1 und 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df['review'].to_numpy()\n",
    "label_data_strings = df['rating']\n",
    "label_data = np.array([int(item.split()[0]) for item in label_data_strings])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Verteilung der Ratings besser zu verstehen koennen wir die Daten visualieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(label_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilung in Trainings und Validierungsdaten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(train_data, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text zu Dictonary Repräsentationen umbauen\n",
    "Als Best Practice für Word Classification gibt das Buch Deep Learning with Python die Nutzung von 20000 Token an.\n",
    "Als Vectorication Mehotik. N-Gramme sind Sequenzen von aufeinanderfolgenden Elementen in einer gegebenen Textsequenz. \n",
    "Ein N-Gramm mit einem Wert von N besteht aus N aufeinanderfolgenden Elementen, die in der Regel Wörter oder Zeichen sind. Zum Beispiel besteht ein 2-Gramm (auch Bigramm genannt) aus zwei aufeinanderfolgenden Wörtern in einem Text, während ein 3-Gramm (Trigramm) aus drei aufeinanderfolgenden Wörtern besteht.\n",
    "\n",
    "Außerdem nutzen wir eine Multi-Hot-Kodierung als Ausgabe.\n",
    "Bei der Multi-Hot-Kodierung wird für jedes Merkmal eine binäre Darstellung verwendet, bei der jedes Merkmal durch eine Position im Vektor repräsentiert wird. Jede Position im Vektor steht für eine mögliche Kategorie des Merkmals. Wenn ein bestimmtes Element eines Merkmals vorhanden ist, wird der entsprechende Wert in der Vektorrepräsentation auf 1 gesetzt. Andernfalls wird der Wert auf 0 gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    " max_tokens=20000,\n",
    "ngrams=2,\n",
    " output_mode=\"multi_hot\",\n",
    " standardize=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization.adapt(train_data) \n",
    "text_vectorization.adapt(test_data) \n",
    "\n",
    "multi_hot_train_data = text_vectorization(train_data)\n",
    "multi_hot_test_data = text_vectorization(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Encoding der Lables\n",
    "Multi Hot Encoding nutzen wir auch für die Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_one_hot = tf.one_hot(train_label, 5)\n",
    "train_label_one_hot.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung eines entsprechenden künstlichen neuronalen Models sowie geeigente Benchmarks\n",
    "Damit wir hier ein Softmax output Layer nutzen können um in 5 Klassen die Daten Klassifizieren können.\n",
    "Als Besonderheit nutzen wir noch ein Drop out Layer. \n",
    "Ein Dropout-Layer ist eine spezielle Art von Schicht in einem neuronalen Netzwerk, die dazu dient, Overfitting (Überanpassung) zu reduzieren. Overfitting tritt auf, wenn ein neuronales Netzwerk sehr gut auf die Trainingsdaten passt, aber eine schlechte Leistung auf neuen, unbekannten Daten zeigt.\n",
    "\n",
    "Der Dropout-Layer funktioniert, indem er während des Trainings zufällig eine bestimmte Anzahl von Ausgabefunktionen (Neuronen) \"auslässt\" oder \"fallen lässt\". Das bedeutet, dass diese Neuronen während eines bestimmten Trainingsdurchlaufs keine Informationen an die nachfolgende Schicht weitergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(max_tokens=20000, hidden_dim=32):\n",
    " inputs = keras.Input(shape=(max_tokens,))\n",
    " x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    " x = layers.Dropout(0.5)(x)\n",
    " outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
    " model = keras.Model(inputs, outputs)\n",
    " model.compile(optimizer=\"rmsprop\",\n",
    " loss=\"categorical_crossentropy\",\n",
    " metrics=[\"accuracy\"], \n",
    " )\n",
    " return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Durchführung von In-sample und Out-of-sample Prognosen sowie Bestimmungen sowie Bestimmung der Prognossegüter anhand geeigneter Metriken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Metric to monitor\n",
    "        patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True,  # Restore the weights of the best epoch\n",
    "    )\n",
    "]\n",
    "history = model.fit(multi_hot_train_data, train_label_one_hot, validation_split=0.2, epochs=10, callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_history_metrics\n",
    "plot_history_metrics(history, ['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_one_hot = tf.one_hot(test_label, 5)\n",
    "model.evaluate(multi_hot_test_data,test_label_one_hot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Wir kommen auf Out-of Samlple accuracy von 45%. Als Ziel haben wir uns 20 % Prozent gesetzt, weil wir 5 verschiedene Lables haben und alles drunter nur Raten wäre. Somit hat unsere Analyse das Ziel erreicht."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
