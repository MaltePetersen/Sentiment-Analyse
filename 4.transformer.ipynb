{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JSBfIPhUEpl2"
      },
      "source": [
        "# Sentiment Analyse mit Transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "auY0w_QaEpl4"
      },
      "source": [
        "Zielsetzung: In diesem Notebook verwenden wir einen Transformer zur Analyse unserer Daten. Basierend auf den Erkenntnissen aus dem vorherigen Kapitel sollte dieser theoretisch eine schlechtere Performance aufweisen als das Bag-of-Words-Modell aus den ersten Notebooks, jedoch besser abschneiden als das LSTM-Modell."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gfObZCUVEpl5"
      },
      "source": [
        "Alle Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qO7-nR_Epl5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduzierte Ausführungszeit durch lokale Ausführung\n",
        "Da nicht jeder über eine leistungsstarke Grafikkarte mit GPU-Unterstützung verfügt, kann die Ausführung von LSTMs zeitaufwändig sein. Eine effektive Alternative zur lokalen Ausführung bietet Google Colab. Dieser Dienst ermöglicht die kostenlose Ausführung des Codes mit GPU-Unterstützung. Obwohl die Authentifizierung bei Diensten wie Kaggle etwas komplexer sein kann, haben wir in den Notebooks Tools integriert, die eine einfache Authentifizierung in Google Colab ermöglichen."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authentifizierung bei Kaggle\n",
        "Navigieren Sie zu https://www.kaggle.com. Gehen Sie dann zu Ihrem [Benutzerprofils](https://www.kaggle.com/me/account) und wählen Sie \"API-Token erstellen\" aus. Dadurch wird die Datei kaggle.json heruntergeladen, die Ihre API-Zugangsdaten enthalten.\n",
        "\n",
        "Führen Sie anschließend die nachstehende Zelle aus, um kaggle.json in Ihrer Colab-Laufzeit hochzuladen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "ozD0wXHNEpl7",
        "outputId": "b9f2d844-ba73-4678-f634-4040f773c7fd"
      },
      "outputs": [],
      "source": [
        "from utils.colab_utils import upload_kaggle_file\n",
        "\n",
        "upload_kaggle_file()\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Herunterladen der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGYJByMzEpl8",
        "outputId": "e7104179-b96f-4e03-9fce-612fef03eb68"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Download McDonalds dataset\n",
        "if not os.path.exists('mcdonalds-store-reviews.zip'):\n",
        "    print(\"Downloading McDonalds dataset...\")\n",
        "    !kaggle datasets download -d nelgiriyewithana/mcdonalds-store-reviews\n",
        "if os.path.exists('mcdonalds-store-reviews.zip'):\n",
        "    print(\"Unzipping McDonalds dataset...\")\n",
        "    !unzip -n mcdonalds-store-reviews.zip\n",
        "\n",
        "# Download IMDB dataset\n",
        "if not os.path.exists('imdb-dataset-of-50k-movie-reviews.zip'):\n",
        "    print(\"Downloading IMDB dataset...\")\n",
        "    !kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "if os.path.exists('imdb-dataset-of-50k-movie-reviews.zip'):\n",
        "    print(\"Unzipping IMDB dataset...\")\n",
        "    !unzip -n imdb-dataset-of-50k-movie-reviews.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prozessierung der Daten\n",
        "Die Prozessierung wird nicht weiterbeschrieben, weil sie identisch zum letzten Notebook ist. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNyP_KqMEpl9"
      },
      "outputs": [],
      "source": [
        "df_mc = pd.read_csv('McDonald_s_Reviews.csv', encoding=\"latin-1\")\n",
        "df_imdb = pd.read_csv('IMDB Dataset.csv')\n",
        "df_mc = df_mc[df_mc['rating'] != '3 stars']\n",
        "data_mc = df_mc['review'].to_numpy()\n",
        "data_imdb = df_imdb['review'].to_numpy()\n",
        "rating_mapping_imdb = {\n",
        "    'positive': 1,\n",
        "    'negative': 0,\n",
        "}\n",
        "\n",
        "label_imdb = df_imdb['sentiment'].map(rating_mapping_imdb).to_numpy()\n",
        "rating_mapping_mc = {\n",
        "    '1 star': 0,\n",
        "    '2 stars': 0,\n",
        "    '4 stars': 1,\n",
        "    '5 stars': 1\n",
        "}\n",
        "\n",
        "label_mc = df_mc['rating'].map(rating_mapping_mc).to_numpy()\n",
        "data = np.append(data_imdb, data_mc)\n",
        "label = np.append(label_imdb,label_mc)\n",
        "\n",
        "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wordembedding\n",
        "Wir nutzen das gleiche Encoding für den Transformer wie schon im lSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF4SJF4GEpl9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(train_data)\n",
        "text_vectorization.adapt(test_data)\n",
        "\n",
        "int_train_ds = text_vectorization(train_data)\n",
        "\n",
        "int_test_ds = text_vectorization(test_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformer-Encoder \n",
        "Self Attention:\n",
        "\n",
        "Bei Self-Attention geht es darum, eine Beziehung zwischen verschiedenen Tokens innerhalb einer Sequenz herzustellen, um die wichtigsten Informationen zu identifizieren und zu betonen. \n",
        "\n",
        "Der Prozess der Self-Attention besteht aus drei grundlegenden Schritten:\n",
        "\n",
        "1. Berechnung von Schlüssel-, Wert- und Abfragevektoren: Jedes Token in der Eingabesequenz wird in drei Vektoren transformiert - Schlüssel (Key), Wert (Value) und Abfrage (Query). \n",
        "\n",
        "\n",
        "2. Berechnung der Aufmerksamkeitsgewichte: Für jedes Token in der Sequenz werden Aufmerksamkeitsgewichte berechnet, um seine Beziehung zu anderen Tokens zu bestimmen. Dies geschieht, indem das Skalarprodukt zwischen dem Abfragevektor des aktuellen Tokens und den Schlüsselvektoren aller anderen Tokens berechnet wird. Durch die Anwendung einer Softmax-Funktion auf diese Skalarprodukte werden die Aufmerksamkeitsgewichte normalisiert.\n",
        "output = sum(values x pairwise-scores(query, keys))\n",
        "\n",
        "3. Aggregation der Wertvektoren: Die Aufmerksamkeitsgewichte werden verwendet, um gewichtete Summen der Wertvektoren zu berechnen. Dies ermöglicht die Gewichtung der relevanten Informationen jedes Tokens entsprechend den Aufmerksamkeitsgewichten. Das Ergebnis ist der aggregierte Ausgabevektor für das aktuelle Token.\n",
        "\n",
        "## Was sind die Query, Keys and Values in unserem Model?\n",
        "In unserem Sequence-to-Sequence-Modell sind die Query, Keys und Values alles die gleichen inputs. Sie repräsentieren die Sequenz selbst, die mit sich selbst verglichen wird, um jedes Token mit Kontextinformationen aus der gesamten Sequenz anzureichern. In diesem Fall werden die Query-, Keys- und Values-Vektoren verwendet, um den Self-Attention-Mechanismus anzuwenden und wichtige Beziehungen und Zusammenhänge innerhalb der Sequenz zu erfassen."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Head Attention \n",
        "Der \"Multi-head attention\" Layer wurde in dem Paper \"Attention is all you need\" eingeführt. Der Begriff \"multi-head\" bezieht sich darauf, dass der Self-Attention Layer in eine Reihe unabhängiger Teilräume aufgeteilt wird. Diese lernen unabhängig voneinander. \n",
        "\n",
        "Die Query, Key und Value Vektoren werden durch drei separate Layern von dichten Projektionen geschickt, was zu drei separaten Vektoren führt. Jeder Vektor wird mit Hilfe von Self Attention verarbeitet, und die drei Ausgaben werden wieder zu einem einzelnen Output zusammengefügt. Jeder solche Teilraum wird als \"head\" bezeichnet.\n",
        "\n",
        "Die dense Layers ermöglichen es der Gesamtschicht wirklich etwas zu lernen, ansonsten würde es sich nur um eine zustandslose Transformation handeln. Darüber hinaus hilft die Verwendung unabhängiger Heads der Schicht dabei, verschiedene Gruppen von Merkmalen für jedes Token zu lernen, wobei die Merkmale innerhalb einer Gruppe miteinander korreliert sind, aber größtenteils unabhängig von Merkmalen in einer anderen Gruppe sind.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"assets/MultiHead.png\" alt=\"Multi Head Attention\" width=\"500\"/>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformer-Encoder \n",
        "Ein Transformer besteht aus einem Encoder und einem Decoder. Für unsere Sentiment-Analyse verwenden wir nur den Encoder, da wir keine neuen Sequenzen generieren müssen. Der Kern des Encoders ist der Multi-Head-Attention-Layer, der gerade erläutert wurde. Zusätzlich enthält der Encoder zusätzliche Dense-Layer, um weitere Beziehungen zwischen den Tokens zu erfassen. Residualverbindungen werden verwendet, um sicherzustellen, dass die Dense-Layer keine Informationen zerstören, und Normalisierungsschichten tragen dazu bei, die Daten auf zum Beispiel einen bestimmten Mittelwert zu normalisieren, was das Training stabiler und schneller macht."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"assets/TransformerEncoder.png\" alt=\"Transformer Encoder\" width=\"500\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU3vFJILEpl-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self Attention Model mit Wordembedding\n",
        "Warum GlobalMaxPooling? Was macht es ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4e_zU-1Epl_",
        "outputId": "1e0f57d7-1073-4de0-e988-11c8ff5852b4"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "  keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",  # Metric to monitor\n",
        "        patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True,  # Restore the weights of the best epoch\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OyL4F6JEpl_",
        "outputId": "0848c4f7-584f-47b6-ed74-28e06b2b82d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.fit(int_train_ds, train_label, validation_split=0.2, epochs=20, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKebkDGNFe3b",
        "outputId": "0aa86a88-b7f2-4a04-a802-a5f9fcc6769c"
      },
      "outputs": [],
      "source": [
        "print(model.evaluate(int_test_ds, test_label))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hinzufügen von PositionalEmbedding\n",
        "Die Ergebnisse mit unserem Transformer-Layer sind bereits vielversprechend. Allerdings nutzen wir bisher nur einen der beiden wesentlichen Bestandteile, die den Transformer so leistungsstark machen: den Self Attention Mechanismus. Bisher hatte unser Modell keine Kenntnis über die Reihenfolge der Wörter, obwohl diese einen großen Unterschied in der Bedeutung des Satzes ausmachen können. Um dies zu verbessern, werden wir das Positional Embedding hinzufügen, um die Reihenfolge der Wörter zu berücksichtigen und so die Leistung unseres Modells weiter zu steigern.\n",
        "\n",
        "Der aktuelle Transformer würde diese beiden Sätze identisch bewerten:\n",
        "\n",
        "> \"Eventough I did _**not**_ like the new mayo formula I was satisfied\"\n",
        "\n",
        "> \"Eventough I did like the new mayo formula I was _**not**_ satisfied\"\n",
        "\n",
        "Ein Ansatz zur Integration von positionellen Daten besteht darin, die Daten sequenziell zu verarbeiten. Dieser Ansatz wird auch von LSTMs verwendet, um positionelle Daten in ihre Modelle einzufügen. Es ist jedoch wichtig zu beachten, dass dieser sequenzielle Ansatz keine parallele Verarbeitung ermöglicht. \n",
        "\n",
        "Im Paper \"Attention is all you need\" wird das Problem der Positionsdaten durch die Anreicherung des Word Embedding Vektors mit positionellen Informationen gelöst. Dieser Ansatz besteht darin, Sinus- und Kosinuswellenfrequenzen zu verwenden, um die Positionsdaten zu kodieren.\n",
        "\n",
        "Anstatt separate Positional Embeddings zu verwenden oder die Daten sequenziell zu verarbeiten, fügt das Paper die Positionsdaten direkt in den Word Embedding Vektor ein. Hierzu werden Sinus- und Kosinusfunktionen mit unterschiedlichen Frequenzen verwendet, um die Positionsinformationen zu kodieren. Diese Sinus- und Kosinuswerte werden dann mit den Word Embedding Vektoren addiert.\n",
        "\n",
        "Durch die Verwendung von Sinus- und Kosinusfrequenzen in den Word Embedding Vektoren kann der Transformer-Modellarchitektur die Positionsinformationen der Wörter erfassen, ohne dass eine sequenzielle Verarbeitung oder separate Positional Embeddings erforderlich sind.\n",
        "\n",
        "\n",
        "Im Bild und der Grafik unter diesem Text wird dies systematisch erklärt. Als Beispiel nehmen wir den Satz:\n",
        "\n",
        " > Die Prüfung war schwer\n",
        " \n",
        "  als unseren Input.\n",
        "\n",
        "Schauen wir uns das Wort \"Prüfung\" genauer an. Zuerst wird ihm ein Index aus dem Wörterbuch zugewiesen. Anschließend wird ein Word Embedding Vektor generiert. In diesem Beispiel werden nur 5 Dimensionen genutzt, während es in der Realität oft deutlich mehr sind. Im Paper \"Attention is all you need\" werden beispielsweise 512 Dimensionen verwendet. Für das Positional Embedding wird ein Vektor mit derselben Größe generiert wie für das Word Embedding.\n",
        "\n",
        "Die Daten in diesem Vektor werden mithilfe der Wortposition (2), der Anzahl der Dimensionen (5) und des Index (0-4) ermittelt. Durch die Indexierung kann das Embedding über verschiedene Frequenzen hinweg die Wortposition vergleichen. Wie in der Grafik zu sehen ist, können zwei Wörter eine ähnliche Frequenz haben, wie zum Beispiel P0 und P2 bei i = 4.\n",
        "\n",
        "Wenn das Modell nur i = 4 verwenden würde, um die Position zu ermitteln, hätte es Schwierigkeiten, die richtige Wortreihenfolge aus den Daten abzuleiten. Glücklicherweise besitzt es jedoch noch weitere Dimensionen, wie z.B. i = 2. In der Grafik können wir sehen, dass sich die Frequenz von P0 und P2 bei i = 2 deutlich unterscheiden.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"assets/PositonalEmbedding.jpeg\" alt=\"PositionalEncoding\" width=\"1000\"/>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"assets/Frequenzen.png\" alt=\"PositionalEncoding\" width=\"500\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y28HIH4NNyTw"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3CIiHtuOATW",
        "outputId": "2308ca41-acb2-4dc3-960c-feaf9f76f66b"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length,vocab_size,embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfhJQJzzOW9v",
        "outputId": "adb5ef82-879d-4a44-df77-83f2a8f30626"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.fit(int_train_ds,train_label, validation_split=0.2, epochs=20, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V3m5sV_OCQd",
        "outputId": "d3038d34-b692-444f-e0d6-2fe95c387981"
      },
      "outputs": [],
      "source": [
        "model.evaluate(int_test_ds, test_label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fazit\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
