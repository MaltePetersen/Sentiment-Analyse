{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "**Ziele**:\n",
    "- Daten verstehen\n",
    "- Eventuelle Probleme identifizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "init_notebook_mode(connected=True)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = [20, 8]\n",
    "plt.rcParams['font.size'] = 18 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herunterladen der Datasets\n",
    "Wir nutzen die Kaggle API um zwei Datensaetze herunterzuladen. Damit die Authentifizierung ohne Probleme funktioniert, muss zunaechst ein Kaggle Account angelegt werden und anschliessend ein enstprechender Access Token generiert werden. \n",
    "\n",
    "Datensaetze:\n",
    "- McDonalds Reviews\n",
    "- IMDB Reviews\n",
    "- (Amazon Food Reviews)\n",
    "\n",
    "**Wichtig:** Falls Google Colab genutzt wird, muss die `kaggle.json` (enthaelt die API credentials) hochgeladen werden. Andernfalls kann der naechste Schritt ubersprungen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "  \n",
    "# Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download McDonalds dataset\n",
    "if not os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Downloading McDonalds dataset...\")\n",
    "    !kaggle datasets download -d nelgiriyewithana/mcdonalds-store-reviews\n",
    "if os.path.exists('mcdonalds-store-reviews.zip'):\n",
    "    print(\"Unzipping McDonalds dataset...\")\n",
    "    !unzip -n mcdonalds-store-reviews.zip\n",
    "\n",
    "# Download IMDB dataset\n",
    "if not os.path.exists('imdb-dataset-of-50k-movie-reviews.zip'):\n",
    "    print(\"Downloading IMDB dataset...\")\n",
    "    !kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "if os.path.exists('imdb-dataset-of-50k-movie-reviews.zip'):\n",
    "    print(\"Unzipping IMDB dataset...\")\n",
    "    !unzip -n imdb-dataset-of-50k-movie-reviews.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusaetzliches Datenset: Amazon Fine Food Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusaetzliches Amazon Review Daa\n",
    "if not os.path.exists('amazon-fine-food-reviews.zip'):  \n",
    "    print(\"Downloading Amazon dataset...\")\n",
    "    !kaggle datasets download -d snap/amazon-fine-food-reviews\n",
    "if os.path.exists('amazon-fine-food-reviews.zip'):  \n",
    "    print(\"Unzipping Amazon dataset...\")\n",
    "    !unzip -n amazon-fine-food-reviews.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Datensaetze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd = pd.read_csv('McDonald_s_Reviews.csv', encoding='latin-1')\n",
    "df_imdb = pd.read_csv('IMDB Dataset.csv')\n",
    "df_amazon = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erster Ueberblick "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**McDonalds Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Amazon Fine Food Reviews)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben Reviewtexten und Bewertungen sind in den Datensaetzen einige weitere Daten enthalten. Da wir folgend nur an den Textdaten und dessen Bewertung interessiert sind, koennen wir diese herausziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the text and the sentiment\n",
    "df_mcd = df_mcd[['review', 'rating']]\n",
    "df_imdb = df_imdb[['review', 'sentiment']]  \n",
    "df_amazon = df_amazon[['Text', 'Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebenfalls koennen wir sehen, dass die Label 'categorical' sind und in form eines strings vorliegen. Um die Label besser verwenden zu koennen werden diese zunaechst in ein numerisches Format umgewandelt. Fuer das Imdb Dataset wird `positive` zu `1` und `negative` zu `0`. Selbes bei den McDonald Reviews, `1 star` entspricht `1` und `5 stars` entspricht `5`. (Im Fall des Amazon Datasets entspricht der 'Score' bereits einem integer Datentypen.)\n",
    "\n",
    "Grundsaetzlich laesst sich bereits sagen, dass die Klassifizierungsprobleme hier einmal eine 'Binary Classification' und einmal eine 'Multi-Class Classification' sind. Fuer die Visualiserung ist dieses zunaechst kein Problem, allerdings muss bei einer spaeteren Zusammenfuerhung beachtet werden inwiefern die kategorialen daten entweder zu positv (1) oder negativ (0) umgewandelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_rating_map = {\n",
    "    '1 star': 1,\n",
    "    '2 stars': 2,\n",
    "    '3 stars': 3,\n",
    "    '4 stars': 4,\n",
    "    '5 stars': 5,\n",
    "}\n",
    "df_mcd['rating'] = df_mcd['rating'].map(mcd_rating_map)\n",
    "df_imdb['sentiment'] = df_imdb['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Align column names\n",
    "df_mcd = df_mcd.rename(columns={'review': 'text', 'rating': 'sentiment'})\n",
    "df_amazon = df_amazon.rename(columns={'Text': 'text', 'Score': 'sentiment'})\n",
    "df_imdb = df_imdb.rename(columns={'review': 'text', 'sentiment': 'sentiment'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das McDonalds und Amazon Dataset haben nachwievor kategorial gelabelte Reviews 1-5, das IMDB Dataset hingegen hat nur binary label mit 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anzal der Eintraege"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"McDonalds dataset has {} entries\".format(len(df_mcd)))\n",
    "for i in range(1, 6):\n",
    "    print(\"McDonalds dataset has {} entries with {} stars\".format(len(df_mcd[df_mcd['sentiment'] == i]), i))\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "print(\"IMDB dataset has {} entries\".format(len(df_imdb)))\n",
    "for i in range(0, 2):\n",
    "    print(\"IMDB dataset has {} entries with {} sentiment\".format(len(df_imdb[df_imdb['sentiment'] == i]), 'positive' if i == 1 else 'negative'))\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "print(\"Amazon dataset has {} entries\".format(len(df_amazon)))\n",
    "for i in range(1, 6):\n",
    "    print(\"Amazon dataset has {} entries with {} stars\".format(len(df_amazon[df_amazon['sentiment'] == i]), i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating / Sentiment Verteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df_mcd)\n",
    "plt.title('McDonalds Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB Sentiment Distribution\n",
    "sns.countplot(x='sentiment', data=df_imdb)\n",
    "plt.title('IMDB Sentiment Distribution')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Rating Distribution\n",
    "sns.countplot(x='sentiment', data=df_amazon)\n",
    "plt.title('Amazon Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genauere Betrachtung das McDonalds Datasets\n",
    "\n",
    "- Charakteranzahl pro Kategorie\n",
    "- Wortanzahl pro Kategorie \n",
    "- Durschnittliche Wortlaenge pro Kategorie\n",
    "- Durchschnittliche Satzlaenge pro Kategorie \n",
    "- Meistvorkommende Woerter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd['char_count'] = df_mcd['text'].apply(len)\n",
    "df_mcd['word_count'] = df_mcd['text'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_mcd['mean_word_length'] = df_mcd['text'].apply(lambda x: np.mean([len(word) for word in word_tokenize(x)]))\n",
    "df_mcd['sent_count'] = df_mcd['text'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_mcd['mean_sent_length'] = df_mcd['word_count'] / df_mcd['sent_count']  \n",
    "df_mcd.head()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='sentiment', y='char_count', data=df_mcd)\n",
    "plt.title('McDonalds Character Count per Review & Category')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Character Count')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='sentiment', y='word_count', data=df_mcd) \n",
    "plt.title('McDonalds Word Count per Review & Category')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence cound per review\n",
    "sns.boxplot(x='sentiment', y='sent_count', data=df_mcd)\n",
    "plt.title('McDonalds Sentence Count per Review & Category')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Sentence Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_lengths = df_mcd.groupby('sentiment').agg({'mean_word_length': 'mean', 'mean_sent_length': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "# Mean Word length\n",
    "sns.barplot(x='sentiment', y='mean_word_length', data=df_mean_lengths, ax=axs[0])\n",
    "axs[0].set_title('Mean Word Length per Rating Category')\n",
    "axs[0].set_xlabel('Rating')\n",
    "axs[0].set_ylabel('Mean Word Length')\n",
    "\n",
    "# Mean Sentence Length \n",
    "sns.barplot(x='sentiment', y='mean_sent_length', data=df_mean_lengths, ax=axs[1])\n",
    "axs[1].set_title('Mean Sentence Length per Rating Category')\n",
    "axs[1].set_xlabel('Rating')\n",
    "axs[1].set_ylabel('Mean Sentence Length')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die vorhergehenden Plots zeigen relativ Interessante Dinge auf. Generell kann gesagt werden, dass schlechte Bewertungen tendenziell laenger sind und mehr Saetze enthalten. Dies deutet darauf hin, dass unzufriedene Kunden detailierteres Feedback geben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up added columns\n",
    "df_mcd.drop(['char_count', 'word_count', 'mean_word_length', 'sent_count', 'mean_sent_length'], axis=1, inplace=True)\n",
    "df_mcd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haeufigkeit von Begriffen\n",
    "Bevor wir die Haeufigkeit von Begriffen analysieren, ist es notwendig, die Datensaetze zu bereinigen, um valide Ergebnisse zu erzielen. Es ist wichtig, irrelevante Daten wie HTML-Tags und Zeichensetzung zu entfernen, da diese in der folgenden Analyse zu Verzerrungen fuehren koennen. Durch die Umwandlung aller Woerter in Kleinbuchstaben erreichen wir eine gewisse Standardisierung, die uns konsistentere Resultate liefert. Zudem erlaubt das Entfernen von Stoppwoertern, die ueblicherweise wenig zur Information beitragen, die Konzentration auf wirklich relevante Begriffe. Dies stellt sicher, dass unsere Analyse praezise und informativ ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinigen der Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    test = text.lower()\n",
    "    # Remove punctuation\n",
    "    test = re.sub(r'[^a-z\\s]', '', test)\n",
    "    # Remove HTML Tags\n",
    "    test = re.sub(r'<.*?>', '', test)\n",
    "    # Remove stopwords\n",
    "    test = ' '.join([word for word in word_tokenize(test) if word not in stopwords.words('english')])\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was hier sicherlich auch noch interessant waere ist 'Stemming' und 'Lemmatization'.\n",
    "- Stemming: Reduziert Woerter auf ihre Basis, z.B. aus 'jumps', 'jumping', 'jumped' wird 'jump'\n",
    "- Lemmatization: Reduziert Woerter auf ihre lexikalische Grundform, bietet hoehere semantische Genauigkeit als Stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_text = df_mcd['text'][0]\n",
    "df_mcd['text'] = df_mcd['text'].apply(clean_text)\n",
    "\n",
    "print('Original Text: {}'.format(og_text))\n",
    "print('Cleaned Text: {}'.format(df_mcd['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anlegen eines Wort - Haeufigkeits Mappings (Aehnlich BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd['word_list'] = df_mcd['text'].apply(lambda x: x.split())\n",
    "df_mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all words and the frequency of each word\n",
    "word_list = []\n",
    "for index, row in df_mcd.iterrows():\n",
    "    word_list += row['word_list']\n",
    "\n",
    "print('Total Words: {}'.format(len(word_list)))\n",
    "most_common_words = Counter(word_list).most_common(10)\n",
    "print('Most Common Words: {}'.format(most_common_words))\n",
    "\n",
    "# Could also use nltk.FreqDist\n",
    "# word_freq = nltk.FreqDist(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for all words and a list for the frequencies\n",
    "words = [word for word,_ in most_common_words]\n",
    "freqs = [freq for _,freq in most_common_words]\n",
    "\n",
    "# plot with seaborn\n",
    "sns.barplot(x=freqs, y=words)\n",
    "plt.title('Top 10 Most Common Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haeufigkeit von Bi-grammen\n",
    "Woerter fuer sich alleine geben meistens nicht den gesamten Kontext wieder. Abhaengig von der Position im Satz koennen sie sogar komplett unterschiedliche Bedeutungen haben. Mit der Betrachtung der Bi-Grams koennen wir ein besseres Verstaendnis fuer den Kontext bekommen, in dem Worte verwendet werden. Des Weiteren hilft diese Analyse gaengige Phrasen und Ausdruecke zu identifizieren, welche haeufig in Reviews verwendet werden, z.B. 'good service', 'cold food' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(df_mcd['text'])\n",
    "\n",
    "print('Total Bigrams: {}'.format(bigrams.shape[1]))\n",
    "print('Shape: {}'.format(bigrams.shape))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_values = bigrams.toarray().sum(axis=0)\n",
    "ngram_freq = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv.vocabulary_.items()], reverse = True))\n",
    "ngram_freq.columns = [\"frequency\", \"ngram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=ngram_freq['frequency'][:10], y=ngram_freq['ngram'][:10])\n",
    "plt.title('Top 10 Most Common Bigrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis auf 'worst mcdonalds' scheinen die Bi-Grams entweder positiv, oder nichts-aussagend zu sein. Hier fehlt uns oft ein weiteres Wort um z.B. bei 'customer service', um eine Bewertung ueber das Sentiment machen zu koennen. Hier waere es interessant zu schauen inwiefern sich die haeufigsten Woerter und BiGramme zwischen negativen und postiven reviews unterscheiden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auftrennung in 'positive' und 'negative' reviews\n",
    "\n",
    "Da die Labels des McDonalds Datensatzes 'multiclass' sind, muss zunaechst eine Entscheidung getroffen werden, welche Reviews 'postiv' und welche 'negativ' sind. Der Einfachheit halber haben wir uns fuer folgende Aufteilung entschieden:\n",
    "- Ratings <= 3 sind negativ\n",
    "- Ratings > 3 sind positiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcd['sentiment'] = df_mcd['sentiment'].map(lambda x: 1 if x > 3 else 0)  \n",
    "df_mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews = df_mcd[df_mcd['sentiment'] == 0]\n",
    "positive_reviews = df_mcd[df_mcd['sentiment'] == 1]\n",
    "\n",
    "print('Number of Negative Reviews: {}'.format(len(negative_reviews)))\n",
    "print('Number of Positive Reviews: {}'.format(len(positive_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all words and the frequency of each word for negative reviews and positive reviews\n",
    "negative_word_list = []\n",
    "for index, row in negative_reviews.iterrows():\n",
    "    negative_word_list += row['word_list']\n",
    "\n",
    "most_common_negative_words = Counter(negative_word_list).most_common(10)\n",
    "neg_freqs = [freq for _,freq in most_common_negative_words]     \n",
    "neg_words = [word for word,_ in most_common_negative_words]\n",
    "\n",
    "positive_word_list = []\n",
    "for index, row in positive_reviews.iterrows():\n",
    "    positive_word_list += row['word_list']\n",
    "\n",
    "most_common_positive_words = Counter(positive_word_list).most_common(10)\n",
    "pos_freqs = [freq for _,freq in most_common_positive_words]\n",
    "pos_words = [word for word,_ in most_common_positive_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with seaborn\n",
    "sns.barplot(x=pos_freqs, y=pos_words)   \n",
    "plt.title('Top 10 Most Common Positive Words')\n",
    "plt.xlabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=neg_freqs, y=neg_words)\n",
    "plt.title('Top 10 Most Common Negative Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_neg = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams_neg = cv_neg.fit_transform(negative_reviews['text'])\n",
    "\n",
    "print('Negative - Total Bigrams: {}'.format(bigrams_neg.shape[1]))\n",
    "print('Shape: {}'.format(bigrams_neg.shape))   \n",
    "\n",
    "cv_pos = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams_pos = cv_pos.fit_transform(positive_reviews['text'])\n",
    "\n",
    "print('Positive - Total Bigrams: {}'.format(bigrams_pos.shape[1]))\n",
    "print('Shape: {}'.format(bigrams_pos.shape))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_values_neg = bigrams_neg.toarray().sum(axis=0)\n",
    "ngram_freq_neg = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv_neg.vocabulary_.items()], reverse = True))\n",
    "ngram_freq_neg.columns = [\"frequency\", \"ngram\"]\n",
    "\n",
    "count_values_pos = bigrams_pos.toarray().sum(axis=0)\n",
    "ngram_freq_pos = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv_pos.vocabulary_.items()], reverse = True))\n",
    "ngram_freq_pos.columns = [\"frequency\", \"ngram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=ngram_freq_pos['frequency'][:10], y=ngram_freq_pos['ngram'][:10])\n",
    "plt.title('Top 10 Most Common Positive Bigrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=ngram_freq_neg['frequency'][:10], y=ngram_freq_neg['ngram'][:10])\n",
    "plt.title('Top 10 Most Common Negative Bigrams')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
